{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Детекция\n",
    "\n",
    "Для детекции я дообучил предобученную модель YOLOv11 medium на видео из сплита train. Обычно, yolo неприхотлива к качеству данных, поэтому я попробовал просто обучить модель на предложенном датасете: я конвертировал его в yolo формат, из гиперпараметров поменял только размер изображения с 640 на 1024, чтобы маленький относительно кадра мяч лучше детектился. Аугментации не использовал.  \n",
    "Обучал около 10 часов на V100 и метрики на валидации получились очень плохими: recall и precision около 0.3.  \n",
    "\n",
    "Вторым вариантом было использовать SAHI на дефолтном для yolo размере изображения - 640x640. Так как sahi не умеет нарезать датасет для yolo, я конвертировал его в coco с помощью библиотеки fiftyone, нарезал и конвертировал обратно в yolo. Это очень времязатратное занятие, поэтому ковертировал я только train часть, из него же взял 0.1 для валидации. Метрики на этой валидационной части получились лучше - recall и precision в районе 0.7, но SAHI я по итогу так и не использовал, т.к., пока учился SAHI, заметил особенности разметки - на некоторых кадрах мяч скрывается, например, за ногами у футболистов и заметить его там невозможно, но разметка все равно присутствует. Я запустил первый вариант детектора на нескольких видео и результаты оказались не такими плохими, как метрики. В дальнейшем использовал первый вариант детектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "model = YOLO(\"runs/detect/train32/weights/last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def draw_detections(path_images, model, output_name='track.avi', video_size=(1920, 1080)):\n",
    "\n",
    "    video=cv2.VideoWriter(output_name,  \n",
    "                          cv2.VideoWriter_fourcc(*\"MJPG\"), \n",
    "                          30, video_size) \n",
    "\n",
    "    for image_name in tqdm(sorted(os.listdir(path_images))):\n",
    "        frame = cv2.imread(os.path.join(path_images, image_name))\n",
    "        \n",
    "        results = model.predict(frame, verbose=False)\n",
    "        \n",
    "        boxes = results[0].boxes.xywh.tolist()\n",
    "        \n",
    "        for box in boxes:\n",
    "            cv2.rectangle(frame, (int(box[0] - box[2] / 2), int(box[1] - box[3] / 2)), \n",
    "                              (int(box[0] + box[2] / 2), int(box[1] + box[3] / 2)),\n",
    "                              (0, 255, 0), 2)\n",
    "        \n",
    "        frame = cv2.resize(frame, video_size)\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видны некоторые проблемы, например, здесь на 14 секунде детектится голова вместо мяча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/double_detection.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/double_detection.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:11<00:00, 10.55it/s]\n"
     ]
    }
   ],
   "source": [
    "draw_detections('data/SoccerNetGS/challenge/SNGS-001/img1', model, output_name='challenge_1.avi', video_size=(1280, 720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь также на 1 и 7 секундах лицо игрока задетектилось как мяч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/challenge_1.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/challenge_1.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:08<00:00, 10.99it/s]\n"
     ]
    }
   ],
   "source": [
    "draw_detections('data/SoccerNetGS/challenge/SNGS-002/img1', model, output_name='challenge_2.avi', video_size=(1280, 720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь тоже периодически голова детектится как мяч + теряется сам мяч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/challenge_2.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/challenge_2.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, мяч детектириуется, видно, что много пропусков кадров, но, кажется, это можно вытянуть алгоритмом трекинга. \n",
    "Для улучшения детекции нужно попробовать добавить аугментаций по освещению, т.к. некоторые видео из challenge явно светлее train, также я бы доделал вариант с SAHI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Трекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачей трекинга я прежде глубоко не занимался, поэтому много времени ушло на то чтобы въехать. Я попробовал несколько классических алгоритмов трекинга из opencv, но ни один не показал хорошего результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее я решил попробовать реализовать простой аналог алгоритма SORT для трекинга одного объекта. Я взял реализацию фильтра Калмана (https://machinelearningspace.com/2d-object-tracking-using-kalman-filter/) с уже заполненными матрицами для предсказания движения 2d объекта, закомменировал компоненты отвечающие за ускорение, так как SORT использует модель движения с константной скоростью. Однако, мне не удалось нормально подобрать значения стандартных отклонений для матриц ковариации - если выставить их большими, то фильтр сильно обращает внимание на предыдущие значения положения мяча и скорости и его начинает колбасить при изменениях траектории, если уменьшить параметры, то не понятно, чем это лучше простого предсказания с помощью модели движения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KalmanFilter(object):\n",
    "    def __init__(self, dt, u_x,u_y, std_acc, x_std_meas, y_std_meas):\n",
    "        \"\"\"\n",
    "        :param dt: sampling time (time for 1 cycle)\n",
    "        :param u_x: acceleration in x-direction\n",
    "        :param u_y: acceleration in y-direction\n",
    "        :param std_acc: process noise magnitude\n",
    "        :param x_std_meas: standard deviation of the measurement in x-direction\n",
    "        :param y_std_meas: standard deviation of the measurement in y-direction\n",
    "        \"\"\"\n",
    "\n",
    "        # Define sampling time\n",
    "        self.dt = dt\n",
    "\n",
    "        # Define the  control input variables\n",
    "        # self.u = np.matrix([[u_x],[u_y]])\n",
    "\n",
    "        # Intial State\n",
    "        self.x = np.matrix([[0], [0], [0], [0]])\n",
    "\n",
    "        # Define the State Transition Matrix A\n",
    "        self.A = np.matrix([[1, 0, self.dt, 0],\n",
    "                            [0, 1, 0, self.dt],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "\n",
    "        # Define the Control Input Matrix B\n",
    "        # self.B = np.matrix([[(self.dt**2)/2, 0],\n",
    "        #                     [0, (self.dt**2)/2],\n",
    "        #                     [self.dt,0],\n",
    "        #                     [0,self.dt]])\n",
    "\n",
    "        # Define Measurement Mapping Matrix\n",
    "        self.H = np.matrix([[1, 0, 0, 0],\n",
    "                            [0, 1, 0, 0]])\n",
    "\n",
    "        #Initial Process Noise Covariance\n",
    "        self.Q = np.matrix([[(self.dt**4)/4, 0, (self.dt**3)/2, 0],\n",
    "                            [0, (self.dt**4)/4, 0, (self.dt**3)/2],\n",
    "                            [(self.dt**3)/2, 0, self.dt**2, 0],\n",
    "                            [0, (self.dt**3)/2, 0, self.dt**2]]) * std_acc**2\n",
    "\n",
    "        #Initial Measurement Noise Covariance\n",
    "        self.R = np.matrix([[x_std_meas**2,0],\n",
    "                           [0, y_std_meas**2]])\n",
    "\n",
    "        #Initial Covariance Matrix\n",
    "        self.P = np.eye(self.A.shape[1])\n",
    "\n",
    "    def predict(self):\n",
    "        # Refer to :Eq.(9) and Eq.(10)  in https://machinelearningspace.com/object-tracking-simple-implementation-of-kalman-filter-in-python/?preview_id=1364&preview_nonce=52f6f1262e&preview=true&_thumbnail_id=1795\n",
    "\n",
    "        # Update time state\n",
    "        #x_k =Ax_(k-1) + Bu_(k-1)     Eq.(9)\n",
    "        self.x = np.dot(self.A, self.x) #+ np.dot(self.B, self.u)\n",
    "\n",
    "        # Calculate error covariance\n",
    "        # P= A*P*A' + Q               Eq.(10)\n",
    "        self.P = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q\n",
    "        return self.x[0:2]\n",
    "    \n",
    "    def update(self, z):\n",
    "\n",
    "        # Refer to :Eq.(11), Eq.(12) and Eq.(13)  in https://machinelearningspace.com/object-tracking-simple-implementation-of-kalman-filter-in-python/?preview_id=1364&preview_nonce=52f6f1262e&preview=true&_thumbnail_id=1795\n",
    "        # S = H*P*H'+R\n",
    "        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R\n",
    "\n",
    "        # Calculate the Kalman Gain\n",
    "        # K = P * H'* inv(H*P*H'+R)\n",
    "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))  #Eq.(11)\n",
    "        \n",
    "        self.x = np.round(self.x + np.dot(K, (z - np.dot(self.H, self.x))))   #Eq.(12)\n",
    "\n",
    "        I = np.eye(self.H.shape[1])\n",
    "\n",
    "        # Update error covariance matrix\n",
    "        self.P = (I - (K * self.H)) * self.P   #Eq.(13)\n",
    "        return self.x[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_kalman(path_images, model, output_name='track.avi', video_size=(1920, 1080)):\n",
    "    video=cv2.VideoWriter(output_name,  \n",
    "                          cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                          30, video_size) \n",
    "\n",
    "    dt = 1 / 30 # 1 секунда / 30 кадров\n",
    "    u_x, u_y = 0, 0\n",
    "    std_acc = 0.1\n",
    "    x_std_meas = 0.01\n",
    "    y_std_meas = 0.01\n",
    "\n",
    "    kf = KalmanFilter(dt, u_x, u_y, std_acc, x_std_meas, y_std_meas)\n",
    "\n",
    "    last_w = 0\n",
    "    last_h = 0\n",
    "\n",
    "    for image_name in tqdm(sorted(os.listdir(path_images))):\n",
    "            frame = cv2.imread(os.path.join(path_images, image_name))\n",
    "\n",
    "            results = model(frame)\n",
    "\n",
    "            out = kf.predict()\n",
    "            x, y = out.A[0], out.A[1]\n",
    "\n",
    "            if len(results[0].boxes) > 0:\n",
    "                xy_det = np.expand_dims(results[0].boxes[0].xyxy[0][:2].cpu().numpy(), 1)\n",
    "                last_w, last_h = results[0].boxes[0].xywh[0][2:].cpu().numpy()\n",
    "\n",
    "                (x1, y1) = kf.update(xy_det)\n",
    "            else:\n",
    "                (x1, y1) = kf.update(np.array([x, y]))\n",
    "\n",
    "            frame = cv2.circle(frame, (int(x + (last_w / 2)), int(y + (last_h / 2))), radius=10, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "            for res in results:\n",
    "                for box in res.boxes:\n",
    "                    b = box.xyxy[0]  \n",
    "                    c = box.cls\n",
    "\n",
    "                    (x_min, y_min, x_max, y_max) = b.tolist()\n",
    "\n",
    "                    # image = np.array(image)\n",
    "\n",
    "                    cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)),\n",
    "                                            (0, 255, 0), 2)\n",
    "            \n",
    "            frame = cv2.resize(frame, video_size)\n",
    "            video.write(frame)\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/750 [00:00<?, ?it/s]/tmp/job-2269450/ipykernel_273708/3266603883.py:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  frame = cv2.circle(frame, (int(x + (last_w / 2)), int(y + (last_h / 2))), radius=10, color=(255, 0, 0), thickness=3)\n",
      "100%|██████████| 750/750 [00:47<00:00, 15.82it/s]\n"
     ]
    }
   ],
   "source": [
    "draw_kalman('data/SoccerNetGS/valid/SNGS-021/img1', model, output_name='double_detection_kalman.avi', video_size=(1280, 720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Синий кружок - предсказание фильтра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/double_detection_kalman.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/double_detection_kalman.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогу я заменил фильтр Калмана простой моделью движения, которая сохраняет последнее положение мяча и вектор скорости, вычисленный по двум последним кадрам. На их основе предсказывается положение мяча в текущем кадре. Если в текущем кадре детектор не нашел мяч, то используется предсказанное положение и последние известные ширина и высота бокса.  \n",
    "\n",
    "Также я попытался решить проблему с детектированием сразу двух мячей в кадре и скачками детекций при потере мяча. Для этого задается радиус поиска, на основе которого и предсказанного положения мяча рассчитывается область поиска. Все задетекченные боксы за пределами этой области отбрасываются. Если внутри области все же осталось несколько боксов - берется с наибольшим confidence.  \n",
    "Если в течение нескольких последних кадров модель не может задетектить мяч, то область поиска отключается и мяч ищется по всему кадру. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "def points_in_circle(boxes, center_x, center_y, radius):\n",
    "    mask = torch.square(boxes[:,0] - torch.full([boxes.shape[0]], center_x, device=device)) + \\\n",
    "           torch.square(boxes[:,1] - torch.full([boxes.shape[0]], center_y, device=device)) <= \\\n",
    "           torch.square(torch.full([boxes.shape[0]], radius, device=device))\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def simple_tracker(path_images, model, output_name='track.avi', radius=150, frames_to_reset=10, video_size=(1920, 1080)):\n",
    "\n",
    "    video=cv2.VideoWriter(output_name,  \n",
    "                          cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                          30, video_size) \n",
    "    \n",
    "    frames_counter = frames_to_reset + 1\n",
    "    \n",
    "    # последние известные параметры трекинга\n",
    "    w_last = 0\n",
    "    h_last = 0\n",
    "    x_last = 0\n",
    "    y_last = 0\n",
    "    v_x = 0 # скорость по x\n",
    "    v_y = 0 # скорость по y\n",
    "\n",
    "    for image_name in tqdm(sorted(os.listdir(path_images))):\n",
    "        frame = cv2.imread(os.path.join(path_images, image_name))\n",
    "\n",
    "        # Положение мяча на основе положения в предыдущем кадре\n",
    "        x_pred = x_last + v_x\n",
    "        y_pred = y_last + v_y\n",
    "        \n",
    "        frame = cv2.arrowedLine(frame, (int(x_last), int(y_last)), (int(x_pred), int(y_pred)), (0, 0, 255), 3)\n",
    "        \n",
    "        results = model.predict(frame, verbose=False)\n",
    "        \n",
    "        # Оставляем только боксы в радиусе предсказанного положения\n",
    "        mask = torch.full([results[0].boxes.xywh.shape[0]], True)\n",
    "        if frames_counter <= frames_to_reset:\n",
    "            mask = points_in_circle(results[0].boxes.xywh, x_pred, y_pred, radius)\n",
    "        \n",
    "        boxes = results[0].boxes.xywh[mask]\n",
    "        confs = results[0].boxes.conf[mask]\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            x_det, y_det, w_det, h_det = boxes[confs.argmax()][:4].tolist()\n",
    "            \n",
    "            # frame = cv2.circle(frame, (int(simple_x + (last_w / 2)), int(simple_y + (last_h / 2))), radius=10, color=(0, 0, 255), thickness=3)\n",
    "            \n",
    "            if frames_counter > frames_to_reset:\n",
    "                v_x = 0\n",
    "                v_y = 0\n",
    "            else:\n",
    "                v_x = x_det - x_last\n",
    "                v_y = y_det - y_last\n",
    "            \n",
    "            x_last = x_det\n",
    "            y_last = y_det\n",
    "            w_last = w_det\n",
    "            h_last = h_det\n",
    "            frames_counter = 0\n",
    "\n",
    "        else:\n",
    "            frames_counter += 1\n",
    "            x_last = x_pred\n",
    "            y_last = y_pred\n",
    "            \n",
    "\n",
    "        # отрисовка радиуса        \n",
    "        #frame = cv2.circle(frame, (int(x_last), int(y_last)), radius=radius, color=(0, 0, 255), thickness=3)\n",
    "        \n",
    "        cv2.rectangle(frame, (int(x_last - w_last / 2), int(y_last - h_last / 2)), \n",
    "                              (int(x_last + w_last / 2), int(y_last + h_last / 2)),\n",
    "                              (0, 255, 0), 2)\n",
    "\n",
    "        frame = cv2.resize(frame, video_size)\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:45<00:00, 16.51it/s]\n"
     ]
    }
   ],
   "source": [
    "simple_tracker('data/SoccerNetGS/valid/SNGS-021/img1', model, output_name='double_detection_tracker.avi', video_size=(1280, 720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что голова начинает детектиться позже (15 секунда) - только когда мяч пропадает из кадра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/double_detection_tracker.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/double_detection_tracker.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:03<00:00, 11.75it/s]\n"
     ]
    }
   ],
   "source": [
    "simple_tracker('data/SoccerNetGS/challenge/SNGS-001/img1', model, output_name='tracker_challenge_1.avi', video_size=(1280, 720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь трекер исключает детекцию головы игрока на 1 и 7 секунде (как это было в видео в начале), но дальше отрабатывает очень плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/tracker_challenge_1.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/tracker_challenge_1.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На втором видео все так же плохо - на 11 секунде детектор теряет мяч, а трекер по вычисленному вектору скорости уводит бокс куда то вниз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/tracker_challenge_2.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/tracker_challenge_2.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогу такой вариант трекера хорошо работает для исключения множественных срабатываний детектора, а также на плавно двигающихся объектах - позволяет заполнить пропуски детекции рассчитанными значениями, но полностью ломается при резком изменении движения - при передачах. С внезапным уводом мяча куда то вниз, как на последнем видео, помог бы правильно настроенный калмановский фильтр или вычисление вектора скользящим средним, но, например, при длительном полете и резкой остановке они, наоборот, будут все портить. Кажется, что в данной задаче подобные решения с фильтрами можно использовать только для примерного расчета положения мяча, а точный трекинг нужно выполнять другими методами.  \n",
    "\n",
    "Конкретно этот алгоритм можно улучшить обучив нормально детектор, сильный буст, скорее всего, даст SAHI. Также после решения проблемы с резким изменением вектора скорости можно попробовать ввести адаптивный радиус поиска, который будет меняться в зависимости от скорости мяча. Также нужно заметить, что в этой задаче камера двигается и зумится, что также влияет на вычисление вектора скорости мяча, можно попробовать корректировать его через трекинг каких нибудь ключевых точек стадиона. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также ради эксперимента я запустил трекер BotSORT из ultralytics. Здесь видны те же проблемы с детекцией голов футболистов, так что обучение модели детекции здесь ключевой момент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def track_botsort(path_images, model, output_name='track.avi', video_size=(1920, 1080)):\n",
    "        \n",
    "        video=cv2.VideoWriter(output_name,  \n",
    "                        cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                        30, video_size) \n",
    "\n",
    "        for image_name in tqdm(sorted(os.listdir(path_images))):\n",
    "                frame = cv2.imread(os.path.join(path_images, image_name))\n",
    "\n",
    "                results = model.track(frame, persist=True, tracker=\"botsort.yaml\")\n",
    "\n",
    "                # Visualize the results on the frame\n",
    "                annotated_frame = results[0].plot(conf=False)\n",
    "                \n",
    "                annotated_frame = cv2.resize(annotated_frame, video_size)\n",
    "                video.write(annotated_frame)\n",
    "                \n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:35<00:00,  7.87it/s]\n"
     ]
    }
   ],
   "source": [
    "track_botsort('data/SoccerNetGS/challenge/SNGS-001/img1', model, output_name='tracker_botsort_challenge_1.avi', video_size=(1280, 720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/tracker_botsort_challenge_1.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/tracker_botsort_challenge_1.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/tracker_botsort_challenge_2.mp4\" controls  width=\"720\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('videos/tracker_botsort_challenge_2.mp4', width=720, height=480) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
